# ğŸ“ Data Engineer Take-Home Assignment

---

# **Overview**

We're working with large-scale conversational audio datasets that include transcripts and metadata. As a data engineer on our team, you'll be responsible for organizing, de-identifying, and preparing this data to be shared with AI model developers and researchers.

This assignment is designed to assess your ability to think clearly about data at scale, privacy-sensitive workflows, and structured dataset curation.

---

## ğŸ¯ Your Objective

Build a lightweight pipeline that:

1. Ingests and organizes audio + transcript data
2. De-identifies *fake* PII from the transcripts
3. Proposes (and optionally stubs) an approach to remove that PII from audio
4. Verifies that de-identification worked
5. Curates and outputs a â€œsellableâ€ dataset structure

Weâ€™ll review both your system design and code. You donâ€™t need to productionize everythingâ€”focus on clarity and practicality.

---

## ğŸ§ª Fake PII Categories

For the purposes of this exercise, treat the following categories as PII:

- Days of the week (e.g., Monday, Tuesday)
- Months (e.g., January, February)
- Colors (e.g., red, blue)
- Cities (e.g., Denver, Seattle)
- States (e.g., Utah, Texas)

Your job is to detect and redact these in transcripts and (optionally) audio.

---

## ğŸ“¦ Dataset

Please use this Hugging Face dataset:

> Appenlimited / 1000h-us-english-smartphone-conversation
> 
> 
> https://huggingface.co/datasets/Appenlimited/1000h-us-english-smartphone-conversation
> 

You do **not** need to use the full dataset. A sample of ~50 conversations is plenty. Design your system to scale, but only process whatâ€™s needed to demonstrate your thinking.

---

## ğŸ“ Deliverables

Youâ€™ll submit two things:

### 1. System Design (written doc, 1â€“2 pages max)

Cover:

- **Storage Architecture:**
    
    How youâ€™d store raw and processed audio, transcripts, metadata, and outputs
    
- **De-Identification Pipeline:**
    - High-level flow
    - Versioning
    - QA methods
    - Assumptions
- **Final Output Structure:**
    - Layout of the sellable dataset
    - Schema for metadata
    - Anything a customer would need to use the data

You can write this in Markdown, Google Docs, Notion, or plain textâ€”whatever is easiest.

---

### 2. Code Submission

You can use any language, but we suggest Python for ease of integration.

Your submission should include:

### A. ğŸ“¥ Data Ingestion

- Load ~50 conversations from the HF dataset
- Store audio, transcripts, and metadata in a logical folder structure
- Generate a basic summary:
    - Number of conversations
    - Total duration
    - Any basic metadata stats

### B. âœ‚ï¸ Transcript De-Identification

- Use a configurable list of fake PII terms
- Replace them with tags like `[CITY]`, `[COLOR]`, etc.
- Handle capitalization, punctuation, and simple variations
- Store the redacted transcripts separately
- Log replacements per conversation

### C. ğŸ”‡ Audio De-ID (Proposal + Optional Stub)

- Describe how you'd:
    - Get word-level timestamps
    - Detect audio spans to redact
    - Mute, bleep, or re-synthesize those spans

Optional: stub or partial implementation (e.g., mute known time ranges).

### D. ğŸ§ª Verification & QA

Include at least one of:

- Script comparing PII counts before/after de-ID
- Sampling tool: show original vs. redacted examples
- Unit tests for your de-ID function

### E. ğŸ“ Dataset Curation

Organize your output as if you were handing it to a paying customer:

Suggested layout:

```
/audio/train/abc123.flac
/transcripts_raw/train/abc123.json
/transcripts_deid/train/abc123.json
/metadata/conversations.parquet
/qa/deid_spot_checks.jsonl

```

Include a metadata row like:

```json
{
  "conversation_id": "abc123",
  "duration_sec": 412.5,
  "num_speakers": 2,
  "sample_rate": 16000,
  "has_pii": true,
  "deid_version": "2025-11-18_v1",
  "qa_status": "approved"
}

```

---

## ğŸ•’ Timebox

This is intended to take **2â€“4 hours of actual work**. Please donâ€™t spend more than that. You can leave parts unfinished or stubbedâ€”just be clear what you would do next.

---

## ğŸ“¤ Submission Instructions

Please send us:

1. A link to your GitHub repo (or zip file)
2. A short written system design doc
3. Optional: a brief note with any assumptions, tradeoffs, or TODOs

Weâ€™re not looking for polish. We want to see how you reason through the problem and handle data practically.

---

Please direct any questions, and your submission to [careers@gosumo.ai](mailto:careers@gosumo.ai) 
Looking forward to your submission.